#%% [markdown]
# # Analyze logs
#
# This script is used to analyze the logs generated by the training process. It can be used to analyze the logs of the training process of the model, and the logs of the evaluation process of the model. The logs of the evaluation process are generated by the `eval.py` script.
#

#%% import packages and functions
import pandas as pd
import numpy as np
from pathlib import Path as pa

def read_log2pd(log_path):
    l = pa(log_path)
    with open(l, 'r') as f:
        lines = f.readlines()
        keys = lines[0].split()
        data = []
        # read till summary
        for line in lines[1:]:
            if 'summary' in line.lower():
                break
            data.append(line.split())
        m_df = pd.DataFrame(data, columns=keys)
        for k in keys:
            if k not in ['id1', 'id2']:
                m_df[k] = m_df[k].astype(np.float64)
        return m_df

def save_log2excel(lmk_log_path, save_exc_dir):
    # create dir if not exist
    for sd in save_exc_dir: sd.mkdir(parents=True, exist_ok=True)
    for sd, l in zip(save_exc_dir, lmk_log_path):
        m_df = read_log2pd(l)
        # add a summary line
        m_df.loc[len(m_df)] = m_df.mean()
        # export pd to excel
        save_file = sd / pa(l).name.replace('.txt', '.xlsx')
        # filter columns that are neither nan or 0
        m_df = m_df.loc[:, ((m_df != 0) & (~m_df.isna())).any(axis=0)]
        m_df.to_excel(save_file, index=False, sheet_name=pa(l).stem)
        m_df.to_csv(sd / pa(l).name.replace('.txt', '.csv'), index=False)
        print('save to {}'.format(save_file))

#%% convert to excel
lmk_log_path = list(pa('/home/hynx/regis/recursive-cascaded-networks/evaluations/').glob('*_lm10*.txt'))
save_exc_dir = [pa('/home/hynx/regis/recursive-cascaded-networks/eval_excel') / lmk_log_path[i].name.split('_')[-2] for i in range(len(lmk_log_path))]

#%% logs that need to be analyzed
log_path = list(pa('/home/hynx/regis/recursive-cascaded-networks/evaluations/').glob('*lits-p*lm10.txt'))
[print(f"{l.name:<50}", end='') for l in log_path];

#%% save all logs in a df
dfs = []
for l in log_path:
    # read file
    print(l.name)
    m_df = read_log2pd(l)
    m_df['log_name'] = l.stem
    dfs.append(m_df)
print('\n')

#%% [markdown]
# ## Analyze the logs of multiple evaluation files
#%% select idxs with 
for df in dfs:
    # only keep id1 that ends with p_115
    extract_id1_id2 = lambda x:x.split('_')[-2:]
    df.drop(df[(df['id2'].apply(extract_id1_id2) == df['id1'].apply(extract_id1_id2))].index, inplace=True)
    df.drop(df[~df['id1'].str.endswith('p_115')].index, inplace=True)
    
keys = ['dice_liver', '3_lmk_err', 'to_ratio']
for i in range(len(dfs)):
    dfs[i]['with_tumor'] = dfs[i]['id2'].str.contains('p_p')
# aggregate results
for df in dfs:
    print("log_name: {}".format(df['log_name'].iloc[0]))
    print(df.groupby('with_tumor')[keys].mean())
    print()
#%%
df

#%% [markdown]
# ## Analyze the logs of a single evaluation file
#%% select df
df = dfs
#%% select idxs with "nt" in id2
df_compared = df[df['id2'].str.contains('p_p') & (df['tl2_ratio'].between(0,1)) & (~df['id1'].str.contains('p_p'))]
# drop index satisfying the condition
df_compared = df_compared[~(df_compared['id2'].apply(lambda x:x.split('_')[-2:]) == df_compared['id1'].apply(lambda x:x.split('_')[-2:]))]
df_selected_id2 = df_compared['id2'].apply(lambda x: x.replace('p_p', 'p_nt'))
df_selected = df[df['id2'].isin(df_selected_id2) & (~df['id1'].str.contains('p_p'))]
print(len(df_selected), len(df_compared))
df_selected
# df_compared

#%% analyze it
keys_to_analyze = ['dice_liver', '3_lmk_err', 'to_ratio']
print('selected df')
for k in keys_to_analyze:
    print(f"{k:<20}", end='')
    print(f"{df_selected[k].mean():.3f} ± {df_selected[k].std():.3f}")

print('df compared')
for k in keys_to_analyze:
    print(f"{k:<20}", end='')
    print(f"{df_compared[k].mean():.3f} ± {df_compared[k].std():.3f}")

#%% plot
import matplotlib.pyplot as plt
independent_var_name = 'tl2_ratio'
dependent_var_name = '3_lmk_err'


# assign tl2_ratio to df_selected according to the correspondance in columm id2
df_selected = df_selected.sort_values(['id2', 'id1'])
df_compared = df_compared.sort_values(['id2','id1'])
df_selected[independent_var_name] = df_compared[independent_var_name].values
# reduce mean
df_selected = df_selected.groupby(independent_var_name).mean().reset_index()
df_compared = df_compared.groupby(independent_var_name).mean().reset_index()
# sorted by tl2_ratio
df_selected = df_selected.sort_values(independent_var_name)
df_compared = df_compared.sort_values(independent_var_name)

# %% plot
independent_var = df_selected[independent_var_name].values
dependent_var = df_selected[dependent_var_name].values
plt.plot(independent_var, dependent_var, '-o')
independent_var = df_compared[independent_var_name].values
dependent_var = df_compared[dependent_var_name].values
plt.plot(independent_var, dependent_var, '-x', color='red')
plt.legend(['selected', 'compared'])
